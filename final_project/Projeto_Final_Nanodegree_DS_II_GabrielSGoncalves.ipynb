{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "### Alterações no script tester.py\n",
    "\n",
    "* Adicionar parênteses no ```print``` do script ```tester.py```\n",
    "* alterar linha de import de biblioteca ```from sklearn.cross_validation import StratifiedShuffleSplit``` para ```from sklearn.model_selection import StratifiedShuffleSplit```\n",
    "\n",
    "### \n",
    "* Copiar ```feature_format.py``` para pasta local\n",
    "\n",
    "### Alterações feitas no poi_id.py\n",
    "* alterar chamada ```with open()``` para usar o segundo para parâmetro como ```rb``` \n",
    "\n",
    "### Estudar aplicação de NMF (Non-negative Matrix Factorization) para o projeto\n",
    "\n",
    "### Ver aplicação de log loss\n",
    "\n",
    "### Orientações na hora de escolher um modelo\n",
    "\n",
    "* Começar sempre com um modelo mais simples e explorar os dados e features\n",
    "* Começar com variáveis númericas\n",
    "* Usar regressão Logistica multi classe\n",
    "    * Treinar o classificador em cada label separadamente e ver desempenho na predição\n",
    "* Como POI são raros, usar StratifiedShuffleSplit\n",
    "* OneVsRestClassifier trata cada coluna de y de forma independente e determina um classificdor  para cada coluna\n",
    "\n",
    "### Usando a função de pipeline do sklearn\n",
    "* Usar ```imputer``` para lidar com dados faltantes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "from tester import dump_classifier_and_data\n",
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para trabalhar com features com informação de texto e numérica no mesmo modelo\n",
    "* Deve-se dividir o processamento de dados numéricos e texto usando ```FunctionTransformer``` e depois ```FeatureUnion``` em ambos os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Split out only the text data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df['text'],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('vec', CountVectorizer),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - just text data: \", accuracy)\n",
    "\n",
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(sample_df)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
    "\n",
    "# Print head to check results\n",
    "print('Text Data')\n",
    "print(just_text_data.head())\n",
    "print('\\nNumeric Data')\n",
    "print(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing', 'text']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all data: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import random forest classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Edit model step in pipeline\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['poi','salary'] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"rb\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salary',\n",
       " 'to_messages',\n",
       " 'deferral_payments',\n",
       " 'total_payments',\n",
       " 'loan_advances',\n",
       " 'bonus',\n",
       " 'email_address',\n",
       " 'restricted_stock_deferred',\n",
       " 'deferred_income',\n",
       " 'total_stock_value',\n",
       " 'expenses',\n",
       " 'from_poi_to_this_person',\n",
       " 'exercised_stock_options',\n",
       " 'from_messages',\n",
       " 'other',\n",
       " 'from_this_person_to_poi',\n",
       " 'poi',\n",
       " 'long_term_incentive',\n",
       " 'shared_receipt_with_poi',\n",
       " 'restricted_stock',\n",
       " 'director_fees']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checando chaves de cada entrada no dicionário\n",
    "list(data_dict.get('ALLEN PHILLIP K').keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enron = pd.DataFrame.from_dict(data_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_enron' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e678f9e1e028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_enron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_enron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoi\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_enron' is not defined"
     ]
    }
   ],
   "source": [
    "df_enron[df_enron.poi ==True].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "salary                       146 non-null object\n",
      "to_messages                  146 non-null object\n",
      "deferral_payments            146 non-null object\n",
      "total_payments               146 non-null object\n",
      "loan_advances                146 non-null object\n",
      "bonus                        146 non-null object\n",
      "email_address                146 non-null object\n",
      "restricted_stock_deferred    146 non-null object\n",
      "deferred_income              146 non-null object\n",
      "total_stock_value            146 non-null object\n",
      "expenses                     146 non-null object\n",
      "from_poi_to_this_person      146 non-null object\n",
      "exercised_stock_options      146 non-null object\n",
      "from_messages                146 non-null object\n",
      "other                        146 non-null object\n",
      "from_this_person_to_poi      146 non-null object\n",
      "poi                          146 non-null bool\n",
      "long_term_incentive          146 non-null object\n",
      "shared_receipt_with_poi      146 non-null object\n",
      "restricted_stock             146 non-null object\n",
      "director_fees                146 non-null object\n",
      "dtypes: bool(1), object(20)\n",
      "memory usage: 24.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_enron.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[201955,\n",
       " 'NaN',\n",
       " 477,\n",
       " 267102,\n",
       " 239671,\n",
       " 80818,\n",
       " 231330,\n",
       " 213999,\n",
       " 'NaN',\n",
       " 216582,\n",
       " 187922,\n",
       " 'NaN',\n",
       " 213625,\n",
       " 248546,\n",
       " 'NaN',\n",
       " 278601,\n",
       " 'NaN',\n",
       " 248017,\n",
       " 261516,\n",
       " 330546,\n",
       " 240189,\n",
       " 261809,\n",
       " 415189,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 288542,\n",
       " 'NaN',\n",
       " 314288,\n",
       " 184899,\n",
       " 206121,\n",
       " 365163,\n",
       " 492375,\n",
       " 210500,\n",
       " 250100,\n",
       " 262788,\n",
       " 221003,\n",
       " 278601,\n",
       " 'NaN',\n",
       " 210692,\n",
       " 182245,\n",
       " 170941,\n",
       " 304588,\n",
       " 440698,\n",
       " 199157,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 1060932,\n",
       " 'NaN',\n",
       " 192008,\n",
       " 231946,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 274975,\n",
       " 272880,\n",
       " 'NaN',\n",
       " 6615,\n",
       " 374125,\n",
       " 243293,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 262663,\n",
       " 211788,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 130724,\n",
       " 85274,\n",
       " 288558,\n",
       " 'NaN',\n",
       " 275101,\n",
       " 404338,\n",
       " 174246,\n",
       " 271442,\n",
       " 309946,\n",
       " 224305,\n",
       " 339288,\n",
       " 1072321,\n",
       " 273746,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 236457,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 349487,\n",
       " 'NaN',\n",
       " 263413,\n",
       " 365038,\n",
       " 'NaN',\n",
       " 370448,\n",
       " 'NaN',\n",
       " 365788,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 267093,\n",
       " 251654,\n",
       " 229284,\n",
       " 'NaN',\n",
       " 329078,\n",
       " 94941,\n",
       " 261879,\n",
       " 'NaN',\n",
       " 655037,\n",
       " 197091,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 96840,\n",
       " 76399,\n",
       " 420636,\n",
       " 249201,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 304110,\n",
       " 269076,\n",
       " 248146,\n",
       " 211844,\n",
       " 'NaN',\n",
       " 428780,\n",
       " 1111258,\n",
       " 239502,\n",
       " 162779,\n",
       " 257486,\n",
       " 265214,\n",
       " 'NaN',\n",
       " 222093,\n",
       " 247338,\n",
       " 26704229,\n",
       " 288589,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 357091,\n",
       " 'NaN',\n",
       " 259996,\n",
       " 63744,\n",
       " 'NaN',\n",
       " 510364,\n",
       " 317543,\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 'NaN',\n",
       " 158403,\n",
       " 'NaN']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_enron.salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
